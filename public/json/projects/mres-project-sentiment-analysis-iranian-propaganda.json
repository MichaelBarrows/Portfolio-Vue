{"id":3,"name":"Sentiment Analysis (Iranian Propaganda)","pretty_url":"mres-project-sentiment-analysis-iranian-propaganda","short_description":"","long_description":"","image":null,"text_logo":null,"fa_icon_logo":"fa-search","created_at":null,"updated_at":null,"content":"<p class=\"all-12\">This project was completed as part of the MRes Technology (Computer Science) course at the University of Portsmouth.<\/p><h3 class=\"all-12\">Summary<\/h3><p class=\"all-12\">This project labelled Iranian state-sponsored propaganda tweets for their sentiment automatically and evaluated the performance of five supervised machine learning algorithms for their ability to accurately classify the sentiment contained in the tweets.<\/p><h3 class=\"all-12\">The Data<\/h3><p class=\"all-12\">This project used tweets from Twitter's election integrity datasets. These datasets consist of tweets from accounts that have been permanently suspended from the Twitter platform as they were identified as belonging to state-sponsored actors and pushed narratives on their behalf.<\/p><h3 class=\"all-12\">Data Extraction<\/h3><p class=\"all-12\">This project was performed on tweets about the Iranian nuclear deal (JCPOA) as it was an internationally controversial issue, that Iran would likely be spreading propaganda about. To extract tweets about the nuclear deal, several keyterms were used (see <a href=\"https:\/\/github.com\/MichaelBarrows\/NuclearDealTweetExtraction\/blob\/master\/original_keywords.csv\" target=\"_blank\">here<\/a>).<\/p><p class=\"all-12\">These keyterms were chosen after analysting the most frequent terms per month across the three (at the time) Iranian releases. Additionally, the extracted tweets were restricted to English and published between August 2013 and December 2018. Retweets were excluded to prevent the machine learning algorithms from developing a bias towards tweets that appear often as retweets.<\/p><h3 class=\"all-12\">Preprocessing<\/h3><p class=\"all-12\">To prepare the tweets for labelling, steps were taken to transform the text in order to achieve the best possible results. These steps included: lowercase conversion, normalising accented letters, removing usernames, transforming hashtags, removing URL's, expanding contractions, removing special characters and removing stopwords. These steps were taken to improve the chance of matching words between the lexicon and the tweets, and to speed up processing.<\/p><h3 class=\"all-12\">Sentiment Labelling<\/h3><p class=\"all-12\">To label the tweets for their sentiment, the SentiWordNet Lexicon was used. This lexicon provides a score between 0 and 1 for both positive and negative sentiments. The lexicon also provides a score between 0 and 1 for objectivity. The sentiment of the tweet was determined by averaging the positive and negative sentiment scores, and identifying which score was higher. If the scores were equal, the tweet was considered neutral.<\/p><h3 class=\"all-12\">Sentiment Analysis (Machine Learning Task)<\/h3><p class=\"all-12\">The machine learning task of sentiment analysis was completed using a metric called Match Percentage Threshold (MPT); this metric represents the number of matches between the tweet and the lexicon as a percentage, with a higher percentage indicating a higher number of matched words. The machine learning tasks were performed across 5 features: unigrams, bigrams, trigrams, unigrams + bigrams, unigrams + bigrams + trigrams. The 5 algorithms used for these experiments were: K-Nearest Neighbours, Decision Tree, Naive Bayes, Support Vector Machine (with a linear kernel), and Random Forest.<\/p><h3 class=\"all-12\">Results<\/h3><p class=\"all-12\">Not yet available.<\/p>","tech_stack_list":"python machine-learning natural-language-processing","project_texts":[{"id":18,"project_id":3,"format":"p class=\"all-12\"","order":1,"text":"This project was completed as part of the MRes Technology (Computer Science) course at the University of Portsmouth.","created_at":null,"updated_at":null},{"id":19,"project_id":3,"format":"h3 class=\"all-12\"","order":2,"text":"Summary","created_at":null,"updated_at":null},{"id":20,"project_id":3,"format":"p class=\"all-12\"","order":3,"text":"This project labelled Iranian state-sponsored propaganda tweets for their sentiment automatically and evaluated the performance of five supervised machine learning algorithms for their ability to accurately classify the sentiment contained in the tweets.","created_at":null,"updated_at":null},{"id":21,"project_id":3,"format":"h3 class=\"all-12\"","order":4,"text":"The Data","created_at":null,"updated_at":null},{"id":22,"project_id":3,"format":"p class=\"all-12\"","order":5,"text":"This project used tweets from Twitter's election integrity datasets. These datasets consist of tweets from accounts that have been permanently suspended from the Twitter platform as they were identified as belonging to state-sponsored actors and pushed narratives on their behalf.","created_at":null,"updated_at":null},{"id":23,"project_id":3,"format":"h3 class=\"all-12\"","order":6,"text":"Data Extraction","created_at":null,"updated_at":null},{"id":24,"project_id":3,"format":"p class=\"all-12\"","order":7,"text":"This project was performed on tweets about the Iranian nuclear deal (JCPOA) as it was an internationally controversial issue, that Iran would likely be spreading propaganda about. To extract tweets about the nuclear deal, several keyterms were used (see <a href=\"https:\/\/github.com\/MichaelBarrows\/NuclearDealTweetExtraction\/blob\/master\/original_keywords.csv\" target=\"_blank\">here<\/a>).","created_at":null,"updated_at":null},{"id":25,"project_id":3,"format":"p class=\"all-12\"","order":8,"text":"These keyterms were chosen after analysting the most frequent terms per month across the three (at the time) Iranian releases. Additionally, the extracted tweets were restricted to English and published between August 2013 and December 2018. Retweets were excluded to prevent the machine learning algorithms from developing a bias towards tweets that appear often as retweets.","created_at":null,"updated_at":null},{"id":26,"project_id":3,"format":"h3 class=\"all-12\"","order":9,"text":"Preprocessing","created_at":null,"updated_at":null},{"id":27,"project_id":3,"format":"p class=\"all-12\"","order":10,"text":"To prepare the tweets for labelling, steps were taken to transform the text in order to achieve the best possible results. These steps included: lowercase conversion, normalising accented letters, removing usernames, transforming hashtags, removing URL's, expanding contractions, removing special characters and removing stopwords. These steps were taken to improve the chance of matching words between the lexicon and the tweets, and to speed up processing.","created_at":null,"updated_at":null},{"id":28,"project_id":3,"format":"h3 class=\"all-12\"","order":11,"text":"Sentiment Labelling","created_at":null,"updated_at":null},{"id":29,"project_id":3,"format":"p class=\"all-12\"","order":12,"text":"To label the tweets for their sentiment, the SentiWordNet Lexicon was used. This lexicon provides a score between 0 and 1 for both positive and negative sentiments. The lexicon also provides a score between 0 and 1 for objectivity. The sentiment of the tweet was determined by averaging the positive and negative sentiment scores, and identifying which score was higher. If the scores were equal, the tweet was considered neutral.","created_at":null,"updated_at":null},{"id":30,"project_id":3,"format":"h3 class=\"all-12\"","order":13,"text":"Sentiment Analysis (Machine Learning Task)","created_at":null,"updated_at":null},{"id":31,"project_id":3,"format":"p class=\"all-12\"","order":14,"text":"The machine learning task of sentiment analysis was completed using a metric called Match Percentage Threshold (MPT); this metric represents the number of matches between the tweet and the lexicon as a percentage, with a higher percentage indicating a higher number of matched words. The machine learning tasks were performed across 5 features: unigrams, bigrams, trigrams, unigrams + bigrams, unigrams + bigrams + trigrams. The 5 algorithms used for these experiments were: K-Nearest Neighbours, Decision Tree, Naive Bayes, Support Vector Machine (with a linear kernel), and Random Forest.","created_at":null,"updated_at":null},{"id":32,"project_id":3,"format":"h3 class=\"all-12\"","order":15,"text":"Results","created_at":null,"updated_at":null},{"id":33,"project_id":3,"format":"p class=\"all-12\"","order":16,"text":"Not yet available.","created_at":null,"updated_at":null}],"tech_stack":[{"id":9,"name":"Python","identifier":"python","is_long":0,"created_at":null,"updated_at":null,"pivot":{"project_id":3,"tech_stack_id":9}},{"id":11,"name":"Machine Learning","identifier":"machine-learning","is_long":1,"created_at":null,"updated_at":null,"pivot":{"project_id":3,"tech_stack_id":11}},{"id":10,"name":"Natural Language Processing","identifier":"natural-language-processing","is_long":1,"created_at":null,"updated_at":null,"pivot":{"project_id":3,"tech_stack_id":10}}]}
